# -*- coding: utf-8 -*-
"""LogReg(v2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/167D0pMQptbJmLVXY_NOH4M-k-AVLl4aS
"""

import numpy as np
import pandas as pd

def pandas_reader(fname):
    df = pd.read_csv(fname)
    return df

def log_regression(train, lambda_val, alpha, learning_rate_decay):

    # Initialize the weight vector w
    num_features = train.shape[1] - 2 #id+label column
    w = np.zeros(num_features)

    # Set up convergence criteria
    convergence_threshold = 1.0e-4
    convergence = False

    # Initialize previous objective function value
    prev_obj_value = 0

    og_train = train.copy()
    train_x = train[list(train.keys())[1:-1]].to_numpy()
    train_y = train["label"].to_numpy()
    og_train = og_train.to_numpy()

    while not convergence:
        np.random.shuffle(og_train)
        # Randomly shuffle the order of example
        # Iterate through the training examples
        for example in og_train:
            x = example[1:-1].copy()  # Feature vector
            y = example[-1]   # Label

            # Compute the probability p
            p = 1 / (1 + np.exp(-np.dot(w, x)))

            # Update the weight vector with L2 regularization
            w += alpha * ((y - p) * x - 2 * lambda_val * w)


        l2_reg = lambda_val * np.linalg.norm(w)**2
        # Compute the current objective function value
        p = 1/(1+np.exp(np.negative(np.dot(train_x,w))))

        obj_value = np.sum(train_y*np.log(p)+(1-train_y)*np.log(1-p)) - l2_reg

        # Check convergence
        change = abs(prev_obj_value - obj_value)
        if change < convergence_threshold:
          convergence = True

        # Update previous objective function value
        prev_obj_value = obj_value

        # Decay the learning rate
        alpha *= learning_rate_decay

    return w
  
def log_prediction(w, test):
  test_x = test[list(test.keys())[1:]].to_numpy()
  probabilities = 1 / (1 + np.exp(-np.dot(test_x, w)))
  predictions = np.where(probabilities >= 0.5, 1, 0)
  return predictions


def main():
    train = pandas_reader('/content/train.csv')
    test = pandas_reader('/content/test_noans.csv')

    # Set the lambda val, alpha rate, and learning rate decay
    lambda_val = 1.0e-6 #1.0e-4 yields 0.73
    alpha = 0.15
    learning_rate_decay = 0.89

    # Perform logistic regression
    w = log_regression(train, lambda_val, alpha, learning_rate_decay)

    predictions = log_prediction(w,test)

    test = test.set_index("id")
    test["label"] = predictions
    test_ans = test["label"]
    test_ans.to_csv("test_ans.csv")


if __name__ == "__main__":
    main()